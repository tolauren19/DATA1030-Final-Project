{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math \n",
    "import scipy.stats as st\n",
    "import warnings\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "randstates = [random.randint(1,200) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full = pd.read_stata('tedsd_puf_2017_edited.dta')\n",
    "full = full[full['DSMCRIT']==5]\n",
    "full = full[full['SERVICES']>5]\n",
    "df = full.take(np.random.permutation(len(full))[:100000])\n",
    "df.to_csv('training_permutation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_permutation.csv')\n",
    "df.drop(columns=['DSMCRIT', 'DISYR', 'CASEID', 'CBSA2010', 'DETNLF', 'DETNLF_D', \n",
    "                 'DIVISION', 'STFIPS', 'MARSTAT', 'PRIMPAY', 'IDU', 'DETCRIM', 'ROUTE2',\n",
    "                 'ROUTE3', 'FREQ2', 'FREQ3', 'FREQ1_D', 'FREQ2_D', 'FREQ3_D', 'HLTHINS',\n",
    "                 'EMPLOY_D', 'SERVICES', 'SERVICES_D', 'FRSTUSE2', 'FRSTUSE3'], inplace=True)\n",
    "df.replace(to_replace = -9, value = np.NaN, inplace = True)\n",
    "df.dropna(subset=['NOPRIOR', 'RACE', 'ETHNIC', 'ARRESTS', 'EDUC', 'EMPLOY', \n",
    "                  'PSOURCE', 'METHUSE', 'GENDER', 'LIVARAG', 'FRSTUSE1', 'ROUTE1', 'FREQ1', 'SUB1'], inplace=True)\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drugs_recode = {1:1, 2:2, 3:3, 4:4, 5:5, 6:5, 7:5, 8:8, 9:8, 10:6, 11:6, 12:8, 13:7, 14:8, 15:8, 16:8, 17:8, 18:8, 19:8}\n",
    "df[['SUB1', 'SUB2', 'SUB3', 'SUB1_D', 'SUB2_D', 'SUB3_D']] = df[\n",
    "    ['SUB1', 'SUB2', 'SUB3', 'SUB1_D', 'SUB2_D', 'SUB3_D']].replace(drugs_recode)\n",
    "\n",
    "ethnic_recode = {1:1, 2:1, 3:1, 4:0, 5:1}\n",
    "df['ETHNIC'] = df['ETHNIC'].replace(ethnic_recode)\n",
    "\n",
    "reasons_recode = {2:0, 3:0, 4:0,5:0, 6:0, 7:0}\n",
    "df['REASON'] = df['REASON'].replace(reasons_recode)\n",
    "\n",
    "df['METHUSE'] = df['METHUSE'].replace({2:0})\n",
    "df['PREG'] = df['PREG'].replace({np.NaN:0, 2:0})\n",
    "df['GENDER'] = df['GENDER'].replace({2:0})\n",
    "df['VET'] = df['VET'].replace({2:0})\n",
    "df['PSYPROB'] = df['PSYPROB'].replace({2:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df['REASON']\n",
    "df.drop(columns=['REASON', 'Unnamed: 0'],inplace=True)\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "race = ['ALASKA_NAT', 'AM_INDIAN', 'API', 'BLACK', 'WHITE', 'ASIAN', 'ONE_R', 'TWO_R', 'HAWAIIAN']\n",
    "livarr = ['HOMELESS', 'DEP_LIV', 'INDEP_LIV']\n",
    "livarr_d = ['LIVARR_D_MISSING', 'HOMELESS_D', 'DEP_LIV_D', 'INDEP_LIV_D']\n",
    "sources = ['INDIV', 'ALC_DRUG_CAREPROV', 'OTHER_CAREPROV', 'SCHOOL', 'EMPLOYER', 'COMM_REF', 'CRIM_JUST']\n",
    "subs1 = ['ALC1', 'COC1', 'MARIJ1', 'HEROIN_OPS1', 'METH1', 'BENZ1', 'OTHER1']\n",
    "subs2 = ['SUBS2_MISSING', 'NONE2', 'ALC2', 'COC2', 'MARIJ2', 'HEROIN_OPS2', 'METH2', 'BENZ2', 'OTHER2']\n",
    "subs3 = ['SUBS3_MISSING', 'NONE3', 'ALC3', 'COC3', 'MARIJ3', 'HEROIN_OPS3', 'METH3', 'BENZ3', 'OTHER3']\n",
    "subs1_d = ['SUBS1_D_MISSING', 'NONE1_D', 'ALC1_D', 'COC1_D', 'MARIJ1_D', 'HEROIN_OPS1_D', 'METH1_D', 'BENZ1_D', 'OTHER1_D']\n",
    "subs2_d = ['SUBS2_D_MISSING', 'NONE2_D', 'ALC2_D', 'COC2_D', 'MARIJ2_D', 'HEROIN_OPS2_D', 'METH2_D', 'BENZ2_D', 'OTHER2_D']\n",
    "subs3_d = ['SUBS3_D_MISSING', 'NONE3_D', 'ALC3_D', 'COC3_D', 'MARIJ3_D', 'HEROIN_OPS3_D', 'METH3_D', 'BENZ3_D', 'OTHER3_D']\n",
    "regions = ['US_TERR', 'NE', 'MW', 'SOUTH', 'WEST']\n",
    "ad_ind = ['ALC_ONLY', 'DRUGS_ONLY', 'ALC_DRUGS']\n",
    "jobs = ['FT', 'PT', 'UNEMP', 'NLF']\n",
    "routes1 = ['ORAL1', 'SMOK1', 'INHAL1', 'INJ1', 'OTHER_ROUTE1']\n",
    "inc = ['INC_MISSING', 'WAGE', 'PUB_ASSIST', 'RET_DIS', 'OTHER', 'NONE']\n",
    "\n",
    "onehot_cols = [regions, sources, livarr, livarr_d, race, subs1, subs2, subs3, subs1_d, subs2_d, subs3_d, ad_ind, jobs, routes1, inc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ML_rf(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    global onehot_cols \n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify=y)\n",
    "\n",
    "    # splitter for _other\n",
    "    skf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    cat_cols = ['REGION', 'PSOURCE', 'LIVARAG', 'LIVARAG_D', 'RACE', \n",
    "                'SUB1', 'SUB2', 'SUB3', 'SUB1_D', 'SUB2_D', 'SUB3_D', 'ALCDRUG', 'EMPLOY', 'ROUTE1', 'PRIMINC']\n",
    "    \n",
    "    cont_cols = ['EDUC', 'LOS', 'ARRESTS', 'ARRESTS_D', 'FREQ1', 'FRSTUSE1', 'AGE', 'ETHNIC', 'GENDER', \n",
    "                 'NOPRIOR', 'PREG', 'DAYWAIT', 'FREQ_ATND_SELF_HELP', 'FREQ_ATND_SELF_HELP_D', \n",
    "                 'METHUSE', 'VET', 'PSYPROB']\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(missing_values = np.NaN, strategy='constant', fill_value = 0)),\n",
    "            ('onehot', OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
    "    \n",
    "    other_transformer = Pipeline(steps=[\n",
    "            ('imputer2', IterativeImputer(missing_values = np.NaN, \n",
    "                                          estimator=RandomForestRegressor(), random_state=random_state))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cont', other_transformer, cont_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)])\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(preprocessor, scaler, RandomForestClassifier(random_state=random_state))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'randomforestclassifier__max_depth': list(range(2, 8)),\n",
    "                 'randomforestclassifier__min_samples_split': list(range(2, 10))}\n",
    "\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score,greater_is_better=True),\n",
    "                        cv=skf, return_train_score = True, iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    #print(grid.cv_results_)\n",
    "    return grid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ML_log(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify=y)\n",
    "\n",
    "    # splitter for _other\n",
    "    skf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    cat_cols = ['REGION', 'PSOURCE', 'LIVARAG', 'LIVARAG_D', 'RACE', \n",
    "                'SUB1', 'SUB2', 'SUB3', 'SUB1_D', 'SUB2_D', 'SUB3_D', 'ALCDRUG', 'EMPLOY', 'ROUTE1', 'PRIMINC']\n",
    "    \n",
    "    cont_cols = ['EDUC', 'LOS', 'ARRESTS', 'ARRESTS_D', 'FREQ1', 'FRSTUSE1', 'AGE', 'ETHNIC', 'GENDER', \n",
    "                 'NOPRIOR', 'PREG', 'DAYWAIT', 'FREQ_ATND_SELF_HELP', 'FREQ_ATND_SELF_HELP_D', \n",
    "                 'METHUSE', 'VET', 'PSYPROB']\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(missing_values = np.NaN, fill_value = 0, strategy='constant')),\n",
    "            ('onehot', OneHotEncoder(categories='auto', sparse=False,handle_unknown='ignore'))])\n",
    "    \n",
    "    other_transformer = Pipeline(steps=[\n",
    "            ('imputer2', IterativeImputer(missing_values = np.NaN, \n",
    "                                          estimator=RandomForestRegressor(), random_state=random_state))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, cat_cols),\n",
    "            ('cont', other_transformer, cont_cols)])\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(preprocessor, scaler, LogisticRegression(solver='saga', max_iter=1000))\n",
    "\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'logisticregression__C': 1/np.logspace(-3,4,num=8),\n",
    "                 'logisticregression__penalty': ['l1', 'l2']}\n",
    "\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score,greater_is_better=True),\n",
    "                        cv=skf, return_train_score = True, iid=True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    #print(grid.cv_results_)\n",
    "    return grid, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372948766128022\n",
      "0.8369660528623325\n",
      "{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "log_grid, log_X_test, log_y_test = ML_log(X,y,42,4)\n",
    "print(log_grid.best_score_)\n",
    "print(log_grid.score(log_X_test,log_y_test))\n",
    "print(log_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('loggrid.save', 'wb')\n",
    "pickle.dump((log_grid, log_X_test,log_y_test),file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8316422397594889\n",
      "0.8322059376174371\n",
      "{'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "rf_grid, rf_X_test, rf_y_test = ML_rf(X,y,42,4)\n",
    "print(rf_grid.best_score_)\n",
    "print(rf_grid.score(rf_X_test,rf_y_test))\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = open('rfgrid.save', 'wb')\n",
    "pickle.dump((rf_grid, rf_X_test,rf_y_test),file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2'}\n",
      "best CV score: 0.8372479017913065\n",
      "test score: 0.8365276211950394\n",
      "Run 1 complete\n",
      "{'logisticregression__C': 0.001, 'logisticregression__penalty': 'l2'}\n",
      "best CV score: 0.8375140924464487\n",
      "test score: 0.8369660528623325\n",
      "Run 2 complete\n",
      "{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2'}\n",
      "best CV score: 0.8378585744707503\n",
      "test score: 0.8358386571464361\n",
      "Run 3 complete\n",
      "test accuracy: 0.8366 +/- 0.0005\n",
      "best test run: 0.8369660528623325 {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "log_test_scores = [log_grid.score(log_X_test,log_y_test)]\n",
    "log_params = [log_grid.best_params_]\n",
    "for i in range(1,4):\n",
    "    grid, X_test, y_test = ML_log(X,y,randstates[i],4)\n",
    "    test_score = grid.score(X_test, y_test)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    log_test_scores.append(test_score)\n",
    "    log_params.append(grid.best_params_)\n",
    "    print('Run %d complete' % i)\n",
    "print('test accuracy:',np.around(np.mean(log_test_scores),4),'+/-',np.around(np.std(log_test_scores),4))\n",
    "log_idx = np.argmax(log_test_scores)\n",
    "print('best test run:', log_test_scores[log_idx], log_params[log_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8369660528623325, 0.8365276211950394, 0.8369660528623325, 0.8358386571464361, 0.8375297507202806]\n",
      "0.8367656269572843\n",
      "0.0005621647418844459\n"
     ]
    }
   ],
   "source": [
    "log_test_scores = [0.8369660528623325, 0.8365276211950394, 0.8369660528623325, 0.8358386571464361, 0.8375297507202806]\n",
    "print(log_test_scores)\n",
    "print(np.mean(log_test_scores))\n",
    "print(np.std(log_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 9}\n",
      "best CV score: 0.8348365276211951\n",
      "test score: 0.8360265564324189\n",
      "Run 1 complete\n",
      "{'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 6}\n",
      "best CV score: 0.8326130527370663\n",
      "test score: 0.8329575347613679\n",
      "Run 2 complete\n",
      "{'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 3}\n",
      "best CV score: 0.8322059376174371\n",
      "test score: 0.8311411749968683\n",
      "Run 3 complete\n",
      "test accuracy: 0.8331 +/- 0.0018\n",
      "best test run: 0.8360265564324189 {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 9}\n"
     ]
    }
   ],
   "source": [
    "rf_test_scores = [rf_grid.score(log_X_test,log_y_test)]\n",
    "rf_params = [rf_grid.best_params_]\n",
    "for i in range(1,4):\n",
    "    grid, X_test, y_test = ML_rf(X,y,randstates[i],4)\n",
    "    test_score = grid.score(X_test, y_test)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    rf_test_scores.append(test_score)\n",
    "    rf_params.append(grid.best_params_)\n",
    "    print('Run %d complete' % i)\n",
    "print('test accuracy:',np.around(np.mean(rf_test_scores),4),'+/-',np.around(np.std(rf_test_scores),4))\n",
    "rf_idx = np.argmax(rf_test_scores)\n",
    "print('best test run:', rf_test_scores[rf_idx], rf_params[rf_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327696354753853\n",
      "0.0017425062937797043\n"
     ]
    }
   ],
   "source": [
    "#rf_test_scores.append(0.8315169735688338)\n",
    "print(np.mean(rf_test_scores))\n",
    "print(np.std(rf_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.171127637581309"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(rf_test_scores) - 0.8123044185755414) / 0.0013489581914233135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.33333333334365"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(log_test_scores) - 0.812351246398597) / np.std(log_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {'logisticregression__C': 0.001, 'logisticregression__penalty': 'l2'}\n",
    "# best CV score: 0.8376393586371038\n",
    "# test score: 0.8375297507202806\n",
    "# Run 0 complete\n",
    "# {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2'}\n",
    "# best CV score: 0.8372479017913065\n",
    "# test score: 0.8365276211950394\n",
    "# Run 1 complete\n",
    "# {'logisticregression__C': 0.001, 'logisticregression__penalty': 'l2'}\n",
    "# best CV score: 0.8375140924464487\n",
    "# test score: 0.8369660528623325\n",
    "# Run 2 complete\n",
    "# {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2'}\n",
    "# best CV score: 0.8378585744707503\n",
    "# test score: 0.8358386571464361\n",
    "# Run 3 complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 2}\n",
    "# best CV score: 0.8340379556557685\n",
    "# test score: 0.8315169735688338\n",
    "# Run 0 complete\n",
    "# {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 9}\n",
    "# best CV score: 0.8348365276211951\n",
    "# test score: 0.8360265564324189\n",
    "# Run 1 complete\n",
    "# {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 6}\n",
    "# best CV score: 0.8326130527370663\n",
    "# test score: 0.8329575347613679\n",
    "# Run 2 complete\n",
    "# {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_split': 3}\n",
    "# best CV score: 0.8322059376174371\n",
    "# test score: 0.8311411749968683\n",
    "# Run 3 complete"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
